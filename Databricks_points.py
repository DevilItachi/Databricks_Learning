- select * from delta.`path` # this is for delta table search
- select * from parquet.`path`  # this is for parquet table search. can give json and csv too
- describe detail table;
- describe extended table;
- % is used to run magic commands
- 2 types of table - managed and external
        - managed table is created in the same location as the data.
            - Deleting manage table deletes the data and metadata. 
        - external table is created in a different location
            - Deleting external table deletes the metadata but not the data. Can undrop the table to restore the data.
        - Manage and external this can created for Catalog, schema, table.
- select current_catalog(), current_schema()
- describe catalog mini_project
- describe schema bronze
- In Unity Catalog , if we drop a managed table, data will not get detleted immediately , but within 7-30 days.
- In Databricks Unity Catalog, dropped objects are soft-deleted, not immediately forgotten
- show tables dropped in schema;  # shows tables dropped within the retention window (â‰ˆ last 7 days)
- undrop table bronze.employees;  # table can be recovered within 7 days with full data.
- show tables in schema;          # shows all table in a schema
- show catalogs like 'eu*'        # shows catalog like eu. use * here
- show schemas in mini_project like '*r*'; 
- show tables in mini_project.bronze like '*ers*'
- describe history  mini_project.bronze.customers  # shows all operation and history on that particular table
- SELECT * FROM mini_project.bronze.customers VERSION AS OF 0   # shows data of that version ..starts from 0
- Temp and Global views
        - create view vw_customers as select * from mini_project.bronze.customers;         # normal view
        - create temporary view tmp_customers as select * from mini_project.bronze.customers # temp view
        - CREATE OR REPLACE GLOBAL TEMP VIEW gb_tmp_customers AS SELECT * FROM mini_project.bronze.customers;  # global temp view
- CTAS (Create Table As Select)
        - Create table  pyspark_python.pyspark.csv_table_tmp  as select * from pyspark_python.pyspark.csv_table; # creates new table with data
- Deep Clone
        - create table pyspark_python.pyspark.csv_table_deep Deep clone pyspark_python.pyspark.csv_table;
        - copy metadata and data both, exact copy of the source table. Delta log is copied. All data files are duplicated. Time travel preserved.
        - Source dependency NO
        - Deep clone is better than CTAS, as in CTAS there is risk of loosing metadata
- Shallow Clone
        - create table pyspark_python.pyspark.csv_table_shallow shallow clone pyspark_python.pyspark.csv_table;
        - copy metadata only. Data files are not copied. Data is referenced from source table. Time travel is not preserved.
        - Source dependency
        - It points to version of source table when we did shadow clone. If source table gets updated shadow table doesnt get updated.
        - It will still point to version of source wehn it ws created.
        - Gets impacted when source table is vaccumed.
- Vacuum
        - vacuum table pyspark_python.pyspark.csv_table_deep retain 0 hours; # deletes all data files older than
- 